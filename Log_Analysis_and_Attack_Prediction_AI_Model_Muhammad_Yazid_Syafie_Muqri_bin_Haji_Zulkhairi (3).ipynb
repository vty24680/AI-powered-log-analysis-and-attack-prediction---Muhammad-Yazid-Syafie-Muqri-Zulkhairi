{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import All Necessary Libraries and Dependencies"
      ],
      "metadata": {
        "id": "GRrgIejUeoho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dependencies\n",
        "!pip install kagglehub[pandas-datasets] pandas scikit-learn matplotlib numpy seaborn"
      ],
      "metadata": {
        "id": "RV0qZ4bglhKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3ZM4acgemed"
      },
      "outputs": [],
      "source": [
        "#Libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Dataset"
      ],
      "metadata": {
        "id": "Kb1wamZ4fUCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies as needed:\n",
        "# pip install kagglehub[pandas-datasets]\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Set the path to the file you'd like to load\n",
        "file_path = \"IoT_Intrusion.csv\"\n",
        "\n",
        "# Load the latest version\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"subhajournal/iotintrusion\",\n",
        "  file_path,\n",
        "  # Provide any additional arguments like\n",
        "  # sql_query or pandas_kwargs. See the\n",
        "  # documenation for more information:\n",
        "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
        ")\n",
        "\n",
        "#Show sample of data\n",
        "df.head()"
      ],
      "metadata": {
        "id": "x4u6A6Snk9iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get column names and shape of data frame\n",
        "print(df.columns[:])\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "L7eM_791fWLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "G4-FOmIrh8An"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Column model will try to predict\n",
        "target_column = 'label'\n",
        "\n",
        "#Column irrelevant to target column\n",
        "excluded_columns = []\n",
        "\n",
        "#Drop rows with missing target value\n",
        "df.dropna(subset=[target_column], inplace=True)\n",
        "\n",
        "\n",
        "#Separate features (X) and target (y)\n",
        "X = df.drop(columns=[target_column] + excluded_columns, errors='ignore')\n",
        "y = df[target_column]\n",
        "\n",
        "#Identify categorical columns for encoding\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "#Apply Label Encoding to categorical features\n",
        "\n",
        "le = LabelEncoder()\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col])\n",
        "    print(f\"Encoded categorical column: {col}\")\n",
        "\n",
        "\n",
        "#Encode the target variable if it's categorical (e.g., 'DDoS', 'PortScan')\n",
        "if y.dtype == 'object' or y.dtype == 'category':\n",
        "    le_y = LabelEncoder()\n",
        "    y = le_y.fit_transform(y)\n",
        "    print(\"Target variable encoded.\")\n",
        "    # You can store le_y to inverse_transform predictions later if needed\n",
        "\n",
        "#Split data into training and testing sets\n",
        "#test_size=0.2\n",
        "#random_state ensures reproducibility of the split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nShape of training features: {X_train.shape}\")\n",
        "print(f\"Shape of testing features: {X_test.shape}\")\n",
        "print(f\"Shape of training target: {y_train.shape}\")\n",
        "print(f\"Shape of testing target: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "DSzZMFNbiB0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training"
      ],
      "metadata": {
        "id": "Awj189RIrzxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "print(\"Training Model...\")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model training complete!\")"
      ],
      "metadata": {
        "id": "mWQwIakZr3FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "OveLyxmOs3ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "#Accuracy Score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "#Classification Report (Precision, Recall, F1-score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=le_y.classes_, zero_division=0))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(18, 15))\n",
        "class_names = le_y.classes_\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 8}, xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix (Raw Counts)')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Feature Importance\n",
        "print(\"\\n--- Feature Importances ---\")\n",
        "feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
        "feature_importances.nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vP1kBtiKs63I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}